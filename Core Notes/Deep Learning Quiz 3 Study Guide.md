Lesson 6, 7, 9

lesson 7: 
- **[Understanding Neural Networks Through Deep VisualizationLinks to an external site.](https://arxiv.org/abs/1506.06579)**
- **[Grad-CAM: Visual Explanations from Deep Networks via Gradient-based LocalizationLinks to an external site.](https://arxiv.org/abs/1610.02391)**
lesson 9: 
#### **Reading Materials:**

- [Fully Convolutional Networks for Semantic SegmentationLinks to an external site.](https://arxiv.org/abs/1605.06211)

#### **Lesson Slides:**

**[M2L9 Advanced Computer Vision Architectures - Slides v3.pdf](https://gatech.instructure.com/courses/346568/files/42273489?wrap=1)**
## Conceptual Questions 
- gram matrix 
- [x] Types of errors and what they mean
- [x] [[Transfer Learning and Generalization]]
- [ ] [[Visualization of Neural Networks]]
- [x] [[Differences between different types of modern architectures (AlexNet, VGGNet, Inception Net, ResNet)]]
- [x] [[Convolutional Neural Networks (CNNs)]]
- [x] [[Invariance vs. Equivariance]]
- [ ] [[Backprop-based visualization]]
- [ ] [[Adversarial Examples]] (Testing Robustness)
- [ ] Loss functions we've covered so far (including style transfer)
- [ ] [[Object detection architectures (including outputs, losses, etc.)]]
- [x] [[Receptive Fields]]
- [ ] [[Transpose convolution]]
- [ ] semantic shift vs non-semantic shift 
- [ ] image segmentation networks, single stage object detection, two-stage object detectors 

## Computation Questions 
- [ ] [[Number of parameters and memory requirements across a CNN (e.g. number of trainable parameters, number of activations)]]
- [ ] [[Forward and backward computation across a convolution layer]]